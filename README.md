## Q1：
#### (a) 
##### i: 
The new prob is 0.491
After changing, $p(\text{Day 1} = H | \text{Observations for Day 1-3})$ is roughly 0.5
Because in the default model, the emission probabilities favor larger numbers of ice creams on hot days, this means that the only two plausible weather sequences are HHH and CHH, other paths (e.g. HCH, CHH ...) are have much smaller probability.
So, $p(\text{Day 1} = H | \text{Observations}) \approx \frac{p(HHH,w)}{p(HHH,w) + p(CHH,w)}$
After replacing Day 1’s observation with 1 ice cream, the term penalizes the HHH path and boosts the CHH path. As a result, the two paths contribute nearly equal total probability: $p(HHH,w) \approx p(CHH,w)$
So, the new prob is roughly 0.5.

##### ii
After changing, $p(\text{Day 1} = H)$ has reduced from roughly 0.9 to about 0.5 as in question (a)i. the uncertainty on Day 1 propagates forward through $p(H|C)$ and $p(H|H)$. The forward probability for Day 2 being Hot becomes a weighted combination of these two possible starting points:
$$p(t_2 = H) \propto p(t_1 = H)p(H|H) + p(t_1 = C)p(H|C)$$
Since $p(t_1 = H)$ dropped, $p(\text{Day 1} = H)$ has also slightly dropped rom about 0.977 to roughly 0.918 in the initial reconstruction.

##### iii:
After 10 iterations of re-estimation:
Day 1: 
p(H) rises from nearly 0 to about 0.557.
The model has partially re-interpreted the “1 ice cream” observation as sometimes compatible with hot days.
Day 2: 
p(H) remains very high (0.993), since its “3 ice cream” observation still overwhelmingly indicates a hot day.
Thus the EM process smooths the probabilities, slightly recovering the Day 1 hot probability while keeping Day 2 confidently hot.

#### (b)
##### i
From the two graphs, the most noticeable difference appears between Days 11–14.
In the original graph (before changing $p(1 | H)$), the model still considers these days to be mostly hot, with $p(H)$ staying around 0.7–0.9 even though ice-cream consumption temporarily drops to 1 or 2.
After setting p(1 | H)=0 and restricting $p(2 | H)=0.3$, the model can no longer explain low ice-cream counts under hot weather.
As a result, during Days 11–14 the pink $p(H)$ line collapses to nearly 0, marking these as cold days.
This sharp dip contrasts with the earlier smooth curve and demonstrates how the strong prior (“never eat 1 ice cream on a hot day”) forces the reconstruction to switch abruptly from Hot to Cold in that mid-period.
After Day 14, when the ice-cream counts rise again, $p(H)$ recovers quickly to values near 1.

ii:
After setting $p(1∣H)=0$, any “1-ice-cream” observation can no longer be generated by the Hot state.
Therefore, even after 10 iterations, the probabilities for those days of “1-ice-cream” remain $p(H)=0$.
The model has reached a fixed point — re-estimation cannot change structural zeros.

##### iii
After 10 iterations, $p(1 | H)$ remains 0. it never increases.

Expectation step (E-step):
During the forward-backward computation, every path in the trellis that would have required a Hot to (1 ice cream) emission now has probability 0.
Therefore, none of the $2^{33}$ possible state sequences that include such emissions contribute any probability mass.
As a result, the expected (fractional) count for the pair (H, 1) is 0.

Maximization step (M-step):
The M-step re-estimates each emission probability as:
$$p(w|t) = \frac{\text{expected} count(t,w)}{\text{expected} count(t)}$$
Since the expected count for (H, 1) = 0, the update yields $p(1∣H)=0$ again.
This repeats on every iteration: each E-step sees zero paths using (H, 1), each M-step keeps it 0.

#### (c)
##### i
Intuitively, $\beta_{bos}(0)$ represents “the probability of generating the entire sentence starting from the beginning-of-sentence tag.”
Just as the forward algorithm ends with $\alpha_{eos}(n+1)$, the backward algorithm begins with $\beta_{bos}(0)$.
Both values equal the overall sentence probability $p(w)$.
$$p(w_1,..,w_n)=\alpha_{eos}(n+1)=\beta_{bos}(0)$$

##### ii
Meaning of an H constituent:
It represents the part of the sentence that is generated while the model is in the Hot state.
Probability of H to 1 C:
$p_B(1|H)*p_A(C|H)$: emit "1" while in Hot, then transition to Cold.

Probability of H to $\epsilon$
$p_A(eos|H)$: terminate the Hot sequence by going to the end-of-sentence symbol.

Why prefer the more complex grammar (with EH/EC):
It separates emission and transition into different rules, making the structure clearer and the inside-style probability computations easier to organize.

## Q2:
#### (a)
Because $\alpha_{BOS}(0)$ and $\beta_{EOS}(n+1)$ are the boundary, and setting them as 1 represents that the valid tag sentence must start from BOS state and end in EOS state. These boundary conditions are suppose to be true not just because they are meant to be in this way theoretically but also as base cases for forward and backward algorithm to propagate with initials and have a neutral multiplicative factor. 

#### (b)
This happens because the raw file is unlabled, and the model can freely marginalize over the tags, matching the data distributaion it was trained on. While the dec file contains fixed labels that may differ in distribution and constrain the model more strictly. Therefore, the perplexity (surprisal) on the dev file is higher. 

The dev perplexity is mmore important, since it reflects the model's generalization ability to unseen labeled data rather than how well it explains its own training distribution.

#### (c)
Because using words from dev to construct V may introduce data leakage. This information leakage might give model unfair prior knowledge of test data, which makes model cheat.

#### (d)
The iterations hurt the overall tagging accuracy. The tagging accuracy overall decreased from 88.63% to 87.035%; the accuracy on known words decreased from 93.06% to 91.39%; the accuracy on seen words increased from 44.11% to 45.79%; and the accuracy on novel words decreasd from 42.73% to 40.29%. 

#### (e)
It sometimes might help because model can learn new words from the context. Through semi-supervised learning, model witnessed some new words in the untagged sentences, and can infer the tag of such new words by the surrounding words that are learned during the supersed learning.


#### (f)
Semi-supervied learning dose not always help is because (1) as iteration goes on, the tagging scheme of model tends to favor the log-likelihood object, which only care which tag being used can best explain the data regardless of the correctness. In such circumstance, the model might tag the words with wrong tags but higher explaination, and those tags are reinforced by iterations since they are kept and might cause further wrong inference on the other word's tagging, degrading emission and transition estimates. As a result, the log-likelihood on the raw data increases but the tagging accuracy decreases. (2) There might exist mismatch between the supervised data and raw data, training on raw data may shift the parameter distribution away from the one trained on the supervised data. 

## Q4
(a)
When trained on the same supervised corpus (ensup) with different parameters,
the CRF achieved much lower cross-entropy (0.42 nats) and higher tagging accuracy (the best is 89%) compared to the HMM (cross-entropy: 7.45 nats, accuracy: 87%).
This demonstrates that discriminative training of p(t∣w) allows the CRF to focus directly on predicting tags rather than modeling the word sequence, giving better generalization on the dev set.

(b)
Adding unlabeled data (enraw) slightly improved the HMM’s log-likelihood (cross-entropy drop from 7.45 to 7.35) and accuracy ($\approx$ +0.5%).
This shows that the HMM can exploit unlabeled sentences through EM by marginalizing over hidden tag sequences.
The CRF, however, cannot use enraw at all, since its conditional objective $logp(t∣w)$ requires gold tags t.
Thus, its results remain unchanged.
The iterations of semi-supervised training can initially help but often end up hurting overall tagging accuracy after a few rounds since the model will more rely on log-likelihood of the raw data, which helps model to explain words regardless of the actual tags. For known words, the accuracy stays the same since their emission prbabilities are well learnt from the supervision data. For seen words, the accuracy might be silghtly improved at first due to the extra contexts, then drop if the log-likelihood is reinforced. For the novel words, they might be slightly improved at first since they could be referrenced by the nearby known words, but they might be even worse as the iteration goes on than seen words since there is little evidence for them, and log-likelihood might easily make the tag to explain them in other direction far away from the correct tags.




